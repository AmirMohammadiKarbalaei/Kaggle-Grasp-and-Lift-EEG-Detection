{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import glob\n",
    "import matplotlib as plt\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scripts_spyder_eegsignals_ import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 1 Data and Events Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(dataa)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = all_labels.append(events)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(dataa)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = all_labels.append(events)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(dataa)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = all_labels.append(events)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(dataa)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = all_labels.append(events)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(dataa)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = all_labels.append(events)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(dataa)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = all_labels.append(events)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(dataa)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = all_labels.append(events)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(dataa)\n",
      "C:\\Users\\amoha\\AppData\\Local\\Temp\\ipykernel_26472\\1811885986.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = all_labels.append(events)\n"
     ]
    }
   ],
   "source": [
    "path_data = \"C:\\\\Users\\\\amoha\\\\Downloads\\\\train\\\\subj1_data\"\n",
    "path_label= \"C:\\\\Users\\\\amoha\\\\Downloads\\\\train\\\\subj1_events\"\n",
    "subj1_data, subj1_label = [] , []\n",
    "for file in glob.glob(path_data + \"\\\\*.csv\"):\n",
    "    subj1_data.append(file)\n",
    "for file in glob.glob(path_label + \"\\\\*.csv\"):\n",
    "    subj1_label.append(file)\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "all_labels = pd.DataFrame()\n",
    "for i,j in zip(subj1_data, subj1_label):\n",
    "    dataa = pd.read_csv(f\"{i}\")\n",
    "    events = pd.read_csv(f\"{j}\")\n",
    "    dataa.drop([\"id\"],axis = 1, inplace = True)\n",
    "    events.drop([\"id\"],axis = 1, inplace = True)\n",
    "    all_data = all_data.append(dataa)\n",
    "    all_labels = all_labels.append(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_data = start_end_data_finder(all_labels)\n",
    "data_extracted_occurances = np.reshape(data_extractor(start_end_data,all_data),(6*260,149,32) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_events_data_extracted = data_extractor_noevent(all_data, all_labels,1560)\n",
    "final_data = np.empty(0*149*32)\n",
    "final_data = np.concatenate((data_extracted_occurances,no_events_data_extracted))\n",
    "final_data = np.reshape(final_data, (3120,149*32))\n",
    "\n",
    "class_labels = np.ones(1560)\n",
    "\n",
    "for i in range(6):\n",
    "    class_labels[i*260:(i+1)*260] = class_labels[i*260:(i+1)*260] *(i)\n",
    "\n",
    "noevent_label = np.ones(1560)*(6)\n",
    "\n",
    "all_class_labels = np.concatenate((class_labels,noevent_label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling and Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "all_data_shuffled , all_labels_shuffled = shuffle(final_data, all_class_labels, random_state = 0)\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "all_data_shuffled_scaled = ss.fit_transform(all_data_shuffled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimentionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "    \n",
    "n_components = 15\n",
    "pca = PCA(n_components = n_components)\n",
    "pca.fit(all_data_shuffled)\n",
    "pca_tr = pca.fit_transform(all_data_shuffled_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### dividing the data into train and test:\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_shuffled_scaled, \n",
    "                                                    all_labels_shuffled, \n",
    "                                                    test_size=0.2, random_state=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Data preprocessing and splitting\n",
    "X = all_data_shuffled_scaled\n",
    "y = all_labels_shuffled\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define hyperparameters and ranges for grid search\n",
    "params = {\n",
    "    'xgbclassifier__eval_metric': ['mlogloss'],  # Wrap 'eval_metric' in XGBClassifier pipeline\n",
    "    'xgbclassifier__use_label_encoder': [False],  # Wrap 'use_label_encoder' in XGBClassifier pipeline\n",
    "    'xgbclassifier__n_jobs': [16],  # Wrap 'n_jobs' in XGBClassifier pipeline\n",
    "    'xgbclassifier__tree_method': ['exact'],  # Wrap 'tree_method' in XGBClassifier pipeline\n",
    "    'xgbclassifier__objective': ['multi:softprob'],  # Wrap 'objective' in XGBClassifier pipeline\n",
    "    'xgbclassifier__random_state': [0],  # Wrap 'random_state' in XGBClassifier pipeline\n",
    "    'xgbclassifier__n_estimators': [100, 150, 200, 250, 300, 350],  # Wrap 'n_estimators' in XGBClassifier pipeline\n",
    "    'xgbclassifier__learning_rate': [0.0001, 0.001, 0.01, 0.1],  # Wrap 'learning_rate' in XGBClassifier pipeline\n",
    "    'xgbclassifier__max_depth': [2, 3, 4, 5, 6, 7, 8, 9],  # Wrap 'max_depth' in XGBClassifier pipeline\n",
    "    'xgbclassifier__gamma': [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],  # Wrap 'gamma' in XGBClassifier pipeline\n",
    "    'xgbclassifier__reg_lambda': [1, 1.5, 2, 3, 4.5],  # Wrap 'reg_lambda' in XGBClassifier pipeline\n",
    "    'xgbclassifier__subsample': [0.8, 0.85, 0.9, 1.0],  # Wrap 'subsample' in XGBClassifier pipeline\n",
    "    'xgbclassifier__colsample_bylevel': np.arange(0.3, 1, 0.1),  # Wrap 'colsample_bylevel' in XGBClassifier pipeline\n",
    "}\n",
    "\n",
    "# Create the XGBoost classifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Create a pipeline with standard scaling and XGBoost classifier\n",
    "pipeline = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "# Perform grid search over hyperparameters\n",
    "grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best model and its accuracy\n",
    "best_model = grid_search.best_estimator_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "XGBoost_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"The best accuracy of XGBoost model is {best_accuracy:.4f}\")\n",
    "print(f\"The accuracy of the best XGBoost model on the test set is {XGBoost_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########Support Vector machines###########\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(kernel =\"rbf\" )\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "SVM_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7628205128205128\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Accuracy:\", SVM_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Random Forest Model###########\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "#Create a Gaussian Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "RandomForest_acc = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7580128205128205\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy:\", RandomForest_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k=5 63.62179487179487\n",
      "Accuracy with k=1 58.493589743589745\n",
      "Accuracy with k=10 65.86538461538461\n"
     ]
    }
   ],
   "source": [
    "#################Implementing K nearest neighbor##############\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn5 = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn10 = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "knn5.fit(X_train, y_train)\n",
    "knn1.fit(X_train, y_train)\n",
    "knn10.fit(X_train, y_train)\n",
    "\n",
    "y_pred_10 = knn10.predict(X_test)\n",
    "y_pred_5 = knn5.predict(X_test)\n",
    "y_pred_1 = knn1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy with k=5\", accuracy_score(y_test, y_pred_5)*100)\n",
    "print(\"Accuracy with k=1\", accuracy_score(y_test, y_pred_1)*100)\n",
    "print(\"Accuracy with k=10\", accuracy_score(y_test, y_pred_10)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
